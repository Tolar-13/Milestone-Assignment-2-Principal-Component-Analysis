{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6ebc4e-569b-4900-9dfb-0c3f974fa57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading, Cleaning and Preprocessing the Breast Cancer dataset from sklearn.datasets used in this project\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "# The dataset is loaded using load_breast_cancer() from sklearn.datasets\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nDataset Info:\\n\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst 5 rows of the dataset:\\n\")\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in the dataset:\\n\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"\\nNumber of duplicate rows in the dataset:\", df.duplicated().sum())\n",
    "\n",
    "# Handle missing values and duplicates if any\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Normalize the data\n",
    "# Using StandardScaler to standardize the features, ensuring they have a mean of 0 and a standard deviation of 1.\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df.drop('target', axis=1))\n",
    "\n",
    "# Display normalized data\n",
    "print(\"\\nNormalized Data (first 5 rows):\\n\")\n",
    "print(X_scaled[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a908fe1f-bc02-47bc-ae4d-66f607f1c406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PCA Implementation\n",
    "\n",
    "# Principal Component Analysis (PCA) will help us identify the most important variables for analysis. \n",
    "# Performing PCA to reduce the dimensions of the dataset and extract meaningful components.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA\n",
    "# We apply PCA to the normalized data with 30 components.\n",
    "pca = PCA(n_components=30)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Explained variance ratio\n",
    "\n",
    "# Explained Variance: We calculate the explained variance ratio for each component to understand how much variance each component captures.\n",
    "# Cumulative Variance: This helps us decide the number of components to retain based on the desired level of explained variance.\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "print(\"Explained Variance Ratio for each component:\\n\")\n",
    "print(explained_variance)\n",
    "print(\"\\nCumulative Explained Variance:\\n\")\n",
    "print(cumulative_variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc32614-b901-40b1-ab78-049f4ac1b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality Reduction\n",
    "# Reducing the dataset to 2 principal components for visualization and analysis\n",
    "\n",
    "# Reduce to 2 components\n",
    "# Reducing Components: The dataset is reduced to two components that capture most of the variance.\n",
    "pca_2 = PCA(n_components=2)\n",
    "X_pca_2 = pca_2.fit_transform(X_scaled)\n",
    "\n",
    "# Explained variance for 2 components\n",
    "# Variance of 2 Components: We observe the explained variance ratio for these two components to verify they capture significant information.\n",
    "explained_variance_2 = pca_2.explained_variance_ratio_\n",
    "print(\"\\nExplained Variance Ratio for 2 components:\\n\")\n",
    "print(explained_variance_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5b5ca5-489f-4c87-a200-30a33e5bfb77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizing PCA Components\n",
    "# Plotting the 2 PCA components to visualize the dataset and identify essential variables for securing donor funding.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Create a scatter plot with seaborn\n",
    "scatter = sns.scatterplot(\n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    hue='target', \n",
    "    data=df_pca,\n",
    "    palette={0: 'blue', 1: 'red'}, # Blue for Benign, Red for Malignant\n",
    "    edgecolor='k', \n",
    "    alpha=0.7,\n",
    "    s=100\n",
    ")\n",
    "\n",
    "# Add plot title and axis labels\n",
    "plt.title('PCA - Breast Cancer Dataset (2 Components)', fontsize=16)\n",
    "plt.xlabel(f'Principal Component 1 ({explained_variance_2[0]*100:.2f}% Variance)', fontsize=14)\n",
    "plt.ylabel(f'Principal Component 2 ({explained_variance_2[1]*100:.2f}% Variance)', fontsize=14)\n",
    "\n",
    "# Custom legend\n",
    "legend_labels = {0: 'Benign', 1: 'Malignant'}\n",
    "handles, labels = scatter.get_legend_handles_labels()\n",
    "scatter.legend(handles=handles, labels=[legend_labels[int(label)] for label in labels], title='Diagnosis', loc='upper right')\n",
    "\n",
    "# Annotations to explain variance\n",
    "plt.annotate(\n",
    "    'PC1 explains ~44.3% variance\\n- High spread indicates significant data separation\\n- Important for donor funding',\n",
    "    xy=(8, 5), xytext=(10, 15),\n",
    "    arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "    fontsize=12, bbox=dict(facecolor='white', alpha=0.8)\n",
    ")\n",
    "\n",
    "plt.annotate(\n",
    "    'PC2 explains ~18.5% variance\\n- Adds further separation between benign and malignant\\n- Less spread than PC1',\n",
    "    xy=(-5, -2), xytext=(-15, -10),\n",
    "    arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "    fontsize=12, bbox=dict(facecolor='white', alpha=0.8)\n",
    ")\n",
    "\n",
    "# Save plot and show\n",
    "plt.savefig('pca_components.png')\n",
    "plt.show()\n",
    "\n",
    "# See README for further details on Key Insights and Visualization Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84099b4-271c-4a43-96c7-207789219724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression \n",
    "# Implementing logistic regression to predict cancer classes based on the reduced dataset.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Splitting the data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca_2, df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression Model \n",
    "# We train a logistic regression model on the 2-component PCA data.\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "# The model's performance is evaluated using accuracy, confusion matrix, and classification report.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"\\nLogistic Regression Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65c0659-5dc6-47f8-a522-4294244d465f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
